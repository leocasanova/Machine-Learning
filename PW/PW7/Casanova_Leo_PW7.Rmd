---
title: "Week 7"
subtitle: "Clustering"
author: Casanova Leo
date: "`r format(Sys.time())`"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: flatly
    highlight: espresso
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# k-means clustering

## 1
Download the dataset: Ligue1 2017-2018  and import it into R. Put the argument row.names to 1.
```{r}
setwd("~/ESILV/A4 - MIF/Machine Learning/PW7")
ligue1 <- read.csv("ligue1_17_18.csv", row.names = 1, sep = ";")
```

## 2 
Print the first two rows of the dataset and the total number of features in this dataset.
```{r}
knitr::kable(ligue1[1:2,])
```

# pointsCards

## 3
We will first consider a smaller dataset to easily understand the results of k-means. Create a new dataset in which you consider only Points and Yellow.cards from the original dataset. Name it pointsCards
```{r}
Points = ligue1$Points
yellow.cards = ligue1$yellow.cards
pointsCards = cbind(Points, yellow.cards)
```

## 4
Apply k-means on pointsCards. Chose k = 2 clusters and put the number of iterations to 20. Store your results into km. (Remark: kmeans() uses a random initialization of the clusters, so the results may vary from one call to another. Use set.seed() to have reproducible outputs).
```{r}
set.seed(211575)
km <- kmeans(pointsCards, centers = 2, iter.max = 20)
```

## 5
Print and describe what is inside km.
```{r}
print(km)
```
There are 2 clusters, one containing 4 observations (football teams), the other one containing 16 observations.
The clusters means represent the coordinates of each centroids.
The clustering vector indicates if the observation (football team) belongs to cluster 1 or cluster 2.


## 6
What are the coordinates of the centers of the clusters (called also prototypes or centroids) ?
```{r}
km$centers
```
The coordinates of the clusters are : C1 (82.00,71.2500) and C2 (44.75, 71.5625) 

## 7
Plot the data (Yellow.cards vs Points). Color the points corresponding to their cluster.
```{r}
plot(pointsCards, col = km$cluster, pch = 19, cex = 2)
```

## 8
Add to the previous plot the clusters centroids and add the names of the observations.
```{r}
plot(pointsCards, col = km$cluster, pch = 19, cex = 2, main = "k-means with 2 clusters", xlab = "Points", ylab = "yellow.cards")
points(km$centers,col=1:3,pch=3,cex=3,lwd=3)
```

## 9
Re-run k-means on pointsCards using 3 and 4 clusters and store the results into km3 and km4 respectively. Visualize the results like in question 7 and 8.
```{r}
km3 <- kmeans(pointsCards,centers=3,iter.max = 20)
km4 <- kmeans(pointsCards,centers=4,iter.max = 20)
plot(pointsCards,col=km3$cluster,pch=19,cex=2,main="k-means with 3 clusters",xlab ="Points",ylab="yellow.cards")
points(km3$centers,col=1:3,pch=3,cex=3,lwd=3) 
plot(pointsCards,col=km4$cluster,pch=19,cex=2,main="k-means with 4 clusters",xlab ="Points",ylab="yellow.cards")
points(km4$centers,col=1:4,pch=3,cex=3,lwd=3) 
```

## 10
Visualize the "within groups sum of squares" of the k-means clustering results (use the code in the link above).
```{r}
mydata <- pointsCards
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(mydata,centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",ylab="Within groups sum of squares", main="within groups sum of squares")
```

## 11
Modify the code of the previous question in order to visualize the 'between_SS / total_SS'. Interpret the results.
```{r}
wss <- 0
for (i in 1:15) wss[i] <- kmeans(mydata,centers=i)$betweenss/kmeans(mydata,centers=i)$totss
plot(1:15, wss, type="b", xlab="Number of Clusters",ylab="between_SS / total_SS", main="between_SS / total_SS")
```

With 3 clusters we cover a ratio of 0.8, so 3 clusters are good for the interpretation.

# Ligue 1

## 12
Scale the dataset and transform it to a data frame again. Store the scaled dataset into ligue1_scaled.
```{r}
ligue1_scaled= scale(ligue1)
```

## 13
Apply kmeans() on ligue1 and on ligue1_scaled using 3 clusters and 20 iterations. Store the results into km.ligue1 and km.ligue1.scaled respectively (do not forget to set a seed)
```{r}
set.seed(211575)
km.ligue1 <- kmeans(ligue1, centers = 3, iter.max = 20)
km.ligue1.scaled <- kmeans(ligue1_scaled, centers=3, iter.max = 20)
```

## 14
How many observations there are in each cluster of km.ligue1 and km.ligue1.scaled ? (you can use table()). Do you obtain the same results when you perform kmeans() on the scaled and unscaled data?
```{r}
table(km.ligue1$cluster)
table(km.ligue1.scaled$cluster)
```
We don't obtain the same results when we perform kmeans() on the scaled and unscaled data.

# PCA

## 15
Apply PCA on ligue1 dataset and store you results in pcaligue1. Do we need to apply PCA on the scaled dataset? Justify your answer.
```{r}
pcaligue1 = princomp(ligue1, cor = T) 
summary(pcaligue1)
```

## 16 
Plot the observations and the variables on the first two principal components (biplot). Interpret the results.
```{r}
library(factoextra)
biplot(pcaligue1)
```

## 17
Visualize the teams on the first two principal components and color them with respect to their cluster.
```{r}
fviz_cluster(km.ligue1, data = ligue1, # km.ligue1 is where you stored your kmeans results
              palette = c("red", "blue", "green"), # 3 colors since 3 clusters
              ggtheme = theme_minimal(),
              main = "Clustering Plot")

```

## 18
Recall that the figure of question 17 is a visualization with PC1 and PC2 of the clustering done with all the variables, not on PC1 and PC2. Now apply the kmeans() clustering taking only the first two PCs instead the variables of original dataset. Visualize the results and compare with the question 17.
```{r}
PC1 <- pcaligue1$scores[,1]
PC2 <- pcaligue1$scores[,2]

X <- cbind(PC1, PC2)
km5 <- kmeans(X, centers = 3)
plot(PC1, PC2, col=km5$cluster, xlab="PC1", ylab="PC2")
points(km5$centers, col=1:3,pch=3,cex=2,lwd=3)
```



